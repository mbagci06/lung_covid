{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Readme.md",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmGwOIIe3CEeAI10emEjul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbagci06/lung_covid/blob/main/Readme_md.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lung and Covid-19 Segmentation With Deep Learning Models \n",
        "## U-Net, DeepLab V3+, Mask R-CNN\n",
        "### Mehmet Furkan BAGCI A59007022\n",
        "### And Kaan Ata YILMAZ A59009346"
      ],
      "metadata": {
        "id": "NWGfWMvWLNuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Run the code for sections \n",
        "Our github repo is created with Colab and any method ratherthan colab takes more time. Code calls the dataset from Kaggle , functions from this Github repo, models from Google Drive. There are 8 train files, 1 test file, 1 plot file. Possible problem about the code is the memory of the GPU\n",
        "#Outline \n",
        "- Train the models \n",
        "- Test the models \n",
        "- Plot the training process \n"
      ],
      "metadata": {
        "id": "3zzv4cFELh7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train models \n",
        "For this project we used this dataset : COVID-QU-Ex[1] Dataset contains 33,920 chest X-ray (CXR) images including their masks. \n",
        "To call and unzipping the dataset takes 3 mins. \n",
        "There are atleast 8 .ipynb file for training, 3 feature model(U-Net, DeepLab v3+), Class(Lung, Covid), method(transfer learning, pretrained) 2*2*2=8  \n",
        "Call this repo for functions \n",
        "```\n",
        "! git clone https://github.com/mbagci06/lung_covid\n",
        "```\n",
        "Call library of Kaggle\n",
        "```\n",
        "! pip install kaggle\n",
        "```\n",
        "Reach the kay file of mine for kaggle and call our dataset\n",
        "```\n",
        "! mkdir ~/.kaggle\n",
        "! cp lung_covid/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d anasmohammedtahir/covidqu\n",
        "```\n",
        "unzip the dataset to archive folder\n",
        "```\n",
        "!unzip \"/content/covidqu.zip\" -d \"/content/archive/\" \n",
        "```\n",
        "The functions and modules for training.\n",
        "```\n",
        "%run lung_covid/functions.ipynb\n",
        "%run lung_covid/DeepLab.ipynb\n",
        "\n",
        "```\n",
        "There might be problem about GPU memory if it is lees then 16GB to fix it change this line and make batch_size smaller.\n",
        "```\n",
        "batch_size=25\n",
        "```\n",
        "\n",
        "The at the end of the code there is saving modules for model and loss,accuracy values. to save them downlaod to your computer or send to your Drive(faster for models) "
      ],
      "metadata": {
        "id": "67ayIUQlrs9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the models \n",
        "The same way we called the Dataset we need to call it again addition to that we have models this time. \n",
        "```\n",
        "gdown helps to download Google Drive files \n",
        "```\n",
        "!pip install gdown\n",
        "\n",
        "This folder has the trained models some of them about 670Mb, downloading from Drive to colab is the fastest. \n",
        "```\n",
        "!gdown --folder https://drive.google.com/drive/folders/1MIzhxSou4TRtQTcG3AADqLag28nj3FrV?usp=sharing\n",
        "```"
      ],
      "metadata": {
        "id": "wu16s_KDtCOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the training process\n",
        "As we called the models we can call the txt files which are created in the training section. \n",
        "To plot we need to call the functions that used in the training. "
      ],
      "metadata": {
        "id": "UBnPs7uMvJbM"
      }
    }
  ]
}